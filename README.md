# Loracle  
### A Privacy-First, On-Device AI Assistant for Android  
### Powered by Ollama running inside Termux  

Loracle is a **privacy-first AI assistant** designed for Android.  
Instead of sending your data to the cloud, Loracle runs fully-local LLMs using **Ollama inside Termux**, ensuring:

- ğŸ’¬ Private chat conversations  
- ğŸ”Š Voice input via Android Speech Recognizer  
- ğŸ”ˆ Natural voice responses via Text-to-Speech  
- ğŸ”Œ Local + Remote LLM support  
- ğŸ§© Modular architecture for future on-device LLMs (llama.cpp)  

Loracle supports **local Ollama instances** running entirely on-device via Termux, and it can also connect to a **remote Ollama server** if configured.

---

## âœ¨ Features

### ğŸ”’ **100% Privacy-Preserving (Local-First)**
All AI processing happens **locally on your phone** via Termux + Ollama.  
Zero cloud APIs. Zero data leaves your device.

### ğŸ¤– **Chat with Local LLMs**
Supports any model available in Ollama, including:

- `gemma:2b`
- `qwen2:1.5b`
- `llama3.2`
- `phi3:mini`
- and any GGUF/GGML-compatible Ollama model

### ğŸ™ï¸ **Voice Assistant Mode**
- Uses Androidâ€™s built-in **SpeechRecognizer** for voice input  
- Replies using Android **Text-to-Speech (TTS)**  
- Hands-free "voice chat" experience entirely offline

### ğŸ”— **Local & Remote LLM**
- Auto-connect to **Termux local Ollama server (`http://127.0.0.1:11434`)**
- Optional support for custom remote endpoints

### ğŸ› ï¸ **Designed for Extensibility**
- Modular architecture
- Future-ready for **integrating llama.cpp models** natively (WIP)
